{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFRICAN LEADERSHIP UNIVERSITY\n",
    "\n",
    "# Artificial Intelligence Course\n",
    "\n",
    "## Assignment #1\n",
    "\n",
    "### Challenge - AI Environment Creation and Testing\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "This is a Group assignment centered on showcasing your technical creativity skills in creating a functional or running environment for implementing AI experiments. The AI implementation environment is to be created on a single node with below mentioned libraries and tools. This will simulate an on-premise hardware environment which will be your machine. This environment should be running specifically on Linux platform (use any preferable distribution and those with Windows Operating System are expected virtualize their environment for Linux installation):\n",
    "\n",
    "1. Latest Anaconda installation.\n",
    "2. Latest version of Python\n",
    "3. Jupyter Notebook\n",
    "4. TensorFlow\n",
    "5. Keras\n",
    "6. NumPy\n",
    "7. SciPy\n",
    "8. Matplotlib\n",
    "9. Pandas\n",
    "10. Scikit-Learn\n",
    "11. Other.\n",
    "\n",
    "#### After creating your environment, you should be able to provide:\n",
    "\n",
    "1. A clear demonstration and explanation of the above mentioned libraries and tools through a specific dataset of your choice. You are free to use any datasets within an African context to provide proper data manipulation operations and procedures as a way of demonstrating functionality of your created environment.\n",
    "\n",
    "2. Necessary comments on your Notebook.\n",
    "\n",
    "3. Documentation of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 1\n",
    "\n",
    "This Group assignment will simulate an on-premise hardware environment which will be your machine. \n",
    "This environment should be running specifically on Linux platform.\n",
    "\n",
    "### 1.0 Linux platform checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\tUbuntu 18.04.5 LTS\r\n"
     ]
    }
   ],
   "source": [
    "# Linux Installation\n",
    "\n",
    "!lsb_release -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 2\n",
    "\n",
    "The AI implementation environment is to be created on a single node with below mentioned libraries and tools.\n",
    "\n",
    "### 1.1 Tools and libraries checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# Latest Anaconda Installation\n",
    "\n",
    "!conda list anaconda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\r\n"
     ]
    }
   ],
   "source": [
    "# Latest Version of Python\n",
    "\n",
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.7.0\n",
      "jupyter-notebook : 6.2.0\n",
      "qtconsole        : 5.0.1\n",
      "ipython          : 7.16.1\n",
      "ipykernel        : 5.4.3\n",
      "jupyter client   : 6.1.11\n",
      "jupyter lab      : not installed\n",
      "nbconvert        : 6.0.7\n",
      "ipywidgets       : 7.6.3\n",
      "nbformat         : 5.1.2\n",
      "traitlets        : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Installation\n",
    "\n",
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Installation\n",
    "\n",
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Installation\n",
    "\n",
    "!pip3 show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy Installation\n",
    "\n",
    "!pip3 show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy Installation\n",
    "\n",
    "!pip3 show scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib Installation\n",
    "\n",
    "!pip3 show matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Installation\n",
    "\n",
    "!pip3 show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Installation\n",
    "\n",
    "!pip3 show scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 3\n",
    "\n",
    "After creating your environment, you should be able to provide:\n",
    "\n",
    "* A clear demonstration and explanation of the above mentioned libraries and tools through a specific dataset of your choice.\n",
    "\n",
    "### 1.2 Importing the libraries to be used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-800b628f1b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing TensorFlow library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Importing TensorFlow library\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Keras library\n",
    "\n",
    "import keras as ks\n",
    "ks.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NumPy library\n",
    "\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SciPy library\n",
    "\n",
    "import scipy as sp\n",
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Matplotlib library\n",
    "\n",
    "import matplotlib as plt\n",
    "plt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas library\n",
    "\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Scikit-Learn library\n",
    "\n",
    "import sklearn as sk\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading the Dataset from CSV file\n",
    "\n",
    "You are free to use any datasets within an African context to provide proper data manipulation operations and procedures as a way of demonstrating functionality of your created environment.\n",
    "\n",
    "The dataset we will use contains information about the Internet Users in Africa.\n",
    "\n",
    "* Dataset link for download or access: [Link] ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and upload csv file \n",
    "\n",
    "# Listing files in working directory\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data from the CSV file and create the dataframe to be used\n",
    "\n",
    "# Load csv file as below\n",
    "df = pd.read_csv(\"AfricaInternetUsers.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Previewing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first 15 rows of data\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Accessing Information about the Dataset\n",
    "\n",
    "Getting to know more about the dataset by accessing its information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data manipulation operations and procedures\n",
    "\n",
    "Provide proper data manipulation operations and procedures as a way of demonstrating functionality of your created environment.\n",
    "\n",
    "### 1.5.0 Data Investigation with TensorFlow\n",
    "\n",
    "TensorFlow is a free and open-source software library for machine learning. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks. Tensorflow is a symbolic math library based on dataflow and differentiable programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Data Investigation with Keras\n",
    "\n",
    "Keras is an open-source software library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library. Up until version 2.3 Keras supported multiple backends, including TensorFlow, Microsoft Cognitive Toolkit, R, Theano, and PlaidML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Data Investigation with Numpy\n",
    "\n",
    "NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Data Investigation with SciPy\n",
    "\n",
    "SciPy is a free and open-source Python library used for scientific computing and technical computing. SciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and other tasks common in science and engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4 Data Investigation with Matplotlib\n",
    "\n",
    "Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.5 Data Investigation with Pandas\n",
    "\n",
    "In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.6 Data Investigation with Scikit-Learn\n",
    "\n",
    "Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
